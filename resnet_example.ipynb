{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN6PtOp5o5yeET8p3fEM8vT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c50490db5fef49e09c7d1b8e775fe291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66bc9433e310423ba3ce9d05def75ad2",
              "IPY_MODEL_63abef7a165c42e9a96278e0554ecd0c",
              "IPY_MODEL_edf3dc5d121a48b4a95baf3759b07840"
            ],
            "layout": "IPY_MODEL_c89bc73b49844d33843252e8fe2845e4"
          }
        },
        "66bc9433e310423ba3ce9d05def75ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2880aeaf04dd46f5a4976ce89e2ed111",
            "placeholder": "​",
            "style": "IPY_MODEL_3e808739eb7b4d2fac573c1cf359e0c4",
            "value": "100%"
          }
        },
        "63abef7a165c42e9a96278e0554ecd0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16711280c15a4d30bb1d16999e502261",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d48e4ec2c49d42a4be4efdf7c6c75285",
            "value": 2
          }
        },
        "edf3dc5d121a48b4a95baf3759b07840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6873bf432eb4fbeb5e877545a9a3e42",
            "placeholder": "​",
            "style": "IPY_MODEL_3e425364dc8c42fda58d6ffc32873e9c",
            "value": " 2/2 [01:02&lt;00:00, 31.13s/it]"
          }
        },
        "c89bc73b49844d33843252e8fe2845e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2880aeaf04dd46f5a4976ce89e2ed111": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e808739eb7b4d2fac573c1cf359e0c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16711280c15a4d30bb1d16999e502261": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d48e4ec2c49d42a4be4efdf7c6c75285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6873bf432eb4fbeb5e877545a9a3e42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e425364dc8c42fda58d6ffc32873e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PietroZamberlan/dino-neuromatch/blob/joel_example/resnet_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "import ipywidgets as widgets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "7OHLoxIBtERi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "VQariPRIBuSA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04bf562-6481-41e7-f743-4cbbde827799"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.94MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 131kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.25MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.97MB/s]\n"
          ]
        }
      ],
      "source": [
        "def load_mnist_data(change_tensors=False, download=True):\n",
        "  \"\"\"\n",
        "  Load training and test examples for the MNIST handwritten digits dataset\n",
        "  with every image: 28*28 x 1 channel (greyscale image)\n",
        "\n",
        "  Args:\n",
        "    change_tensors: Bool\n",
        "      Argument to check if tensors need to be normalised\n",
        "    download: Bool\n",
        "      Argument to check if dataset needs to be downloaded/already exists\n",
        "\n",
        "  Returns:\n",
        "    train_set:\n",
        "      train_data: Tensor\n",
        "        training input tensor of size (train_size x 784)\n",
        "      train_target: Tensor\n",
        "        training 0-9 integer label tensor of size (train_size)\n",
        "    test_set:\n",
        "      test_data: Tensor\n",
        "        test input tensor of size (test_size x 784)\n",
        "      test_target: Tensor\n",
        "        training 0-9 integer label tensor of size (test_size)\n",
        "  \"\"\"\n",
        "  # Load train and test sets\n",
        "  train_set = datasets.MNIST(root='.', train=True, download=download,\n",
        "                             transform=torchvision.transforms.ToTensor())\n",
        "  test_set = datasets.MNIST(root='.', train=False, download=download,\n",
        "                            transform=torchvision.transforms.ToTensor())\n",
        "\n",
        "  # Original data is in range [0, 255]. We normalize the data wrt its mean and std_dev.\n",
        "  # Note that we only used *training set* information to compute mean and std\n",
        "  mean = train_set.data.float().mean()\n",
        "  std = train_set.data.float().std()\n",
        "\n",
        "  if change_tensors:\n",
        "    # Apply normalization directly to the tensors containing the dataset\n",
        "    train_set.data = (train_set.data.float() - mean) / std\n",
        "    test_set.data = (test_set.data.float() - mean) / std\n",
        "  else:\n",
        "    tform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
        "                                            torchvision.transforms.Normalize(mean=[mean / 255.], std=[std / 255.])\n",
        "                                            ])\n",
        "    train_set = datasets.MNIST(root='.', train=True, download=download,\n",
        "                               transform=tform)\n",
        "    test_set = datasets.MNIST(root='.', train=False, download=download,\n",
        "                              transform=tform)\n",
        "\n",
        "  return train_set, test_set\n",
        "\n",
        "\n",
        "train_set, test_set = load_mnist_data(change_tensors=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "T8D2W4YnBuSL"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, loss_fn, data_loader, num_batches=np.inf, device='cpu'):\n",
        "  \"\"\"\n",
        "  To evaluate a given model\n",
        "\n",
        "  Args:\n",
        "    model: nn.Module derived class\n",
        "      The model which is to be evaluated\n",
        "    data_loader: Iterable\n",
        "      A configured dataloading utility\n",
        "    num_batches: Integer\n",
        "      Size of minibatches\n",
        "    device: String\n",
        "      Sets the device. CUDA if available, CPU otherwise\n",
        "\n",
        "  Returns:\n",
        "    mean of log loss and mean of log accuracy\n",
        "  \"\"\"\n",
        "\n",
        "  loss_log, acc_log = [], []\n",
        "  model.to(device=device)\n",
        "\n",
        "  # We are just evaluating the model, no need to compute gradients\n",
        "  with torch.no_grad():\n",
        "    for batch_id, batch in enumerate(data_loader):\n",
        "      # If we only evaluate a number of batches, stop after we reach that number\n",
        "      if batch_id > num_batches:\n",
        "        break\n",
        "      # Extract minibatch data\n",
        "      data, labels = batch[0].to(device), batch[1].to(device)\n",
        "      # Evaluate model and loss on minibatch\n",
        "      preds = model(data)\n",
        "      preds = torch.nn.functional.softmax(preds, dim=-1)\n",
        "      loss_log.append(loss_fn(preds, labels).item())\n",
        "      acc_log.append(torch.mean(1. * (preds.argmax(dim=1) == labels)).item())\n",
        "\n",
        "  return np.mean(loss_log), np.mean(acc_log)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Set device (GPU or CPU). Execute `set_device()`\n",
        "# especially if torch modules used.\n",
        "\n",
        "# Inform the user if the notebook uses GPU or CPU.\n",
        "\n",
        "def set_device():\n",
        "  \"\"\"\n",
        "  Set the device. CUDA if available, CPU otherwise\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"WARNING: For this notebook to perform best, \"\n",
        "        \"if possible, in the menu under `Runtime` -> \"\n",
        "        \"`Change runtime type.`  select `GPU` \")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook.\")\n",
        "\n",
        "  return device"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GxkL34_H3yzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "GtfBsrXehndf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Set random seed\n",
        "\n",
        "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
        "\n",
        "# For DL its critical to set the random seed so that students can have a\n",
        "# baseline to compare their results to expected results.\n",
        "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  \"\"\"\n",
        "  Function that controls randomness.\n",
        "  NumPy and random modules must be imported.\n",
        "\n",
        "  Args:\n",
        "    seed : Integer\n",
        "      A non-negative integer that defines the random state. Default is `None`.\n",
        "    seed_torch : Boolean\n",
        "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
        "      must be imported. Default is `True`.\n",
        "\n",
        "  Returns:\n",
        "    Nothing.\n",
        "  \"\"\"\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n",
        "\n",
        "\n",
        "# In case that `DataLoader` is used\n",
        "def seed_worker(worker_id):\n",
        "  \"\"\"\n",
        "  DataLoader will reseed workers following randomness in\n",
        "  multi-process data loading algorithm.\n",
        "\n",
        "  Args:\n",
        "    worker_id: integer\n",
        "      ID of subprocess to seed. 0 means that\n",
        "      the data will be loaded in the main process\n",
        "      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 2021\n",
        "set_seed(seed=SEED)\n",
        "DEVICE = set_device()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNUfCrBA3wUw",
        "outputId": "fc8a732c-dbd3-4e16-b877-fba77057434b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed 2021 has been set.\n",
            "GPU is enabled in this notebook.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualLinearBlock(nn.Module):\n",
        "  def __init__(self, units):\n",
        "    super(ResidualLinearBlock, self).__init__()\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc1 = nn.Linear(units, units)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # Go forward on the blocks\n",
        "    identity = x # Take the residual from input\n",
        "    x = self.relu(x)\n",
        "    x = self.fc1(x)\n",
        "    # Add the residual to the output of the blocks\n",
        "    x += identity\n",
        "    x = x * (1 / np.sqrt(2))\n",
        "    return x"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yc5tNsNJ9p5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels:int, kernel_size:int, stride:int, downsample:bool=False):\n",
        "    super(ResidualConvBlock, self).__init__()\n",
        "    self.relu = nn.ReLU(inplace=True) #inplace = True optimises by performing the ReLu in-place (no new Tensor is created)\n",
        "    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding='same')\n",
        "    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride, padding='same')\n",
        "\n",
        "    self.batchnorm1 = nn.BatchNorm2d(out_channels)\n",
        "    self.batchnorm2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    self.downsample = downsample\n",
        "    if self.downsample:\n",
        "      self.downsampler = nn.MaxPool2d(2, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # Go forward on the blocks\n",
        "    identity = x # Take the residual from input\n",
        "    x = self.conv1(x)\n",
        "    x = self.batchnorm1(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.batchnorm2(x)\n",
        "\n",
        "\n",
        "\n",
        "    # Add the residual to the output of the blocks\n",
        "    x += identity\n",
        "\n",
        "    if self.downsample:\n",
        "      x = self.downsampler(x)\n",
        "\n",
        "    x = self.relu(x)\n",
        "\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ia_NvPUjBazD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# He initialization of weights\n",
        "def weights_init(layer_in):\n",
        "  if isinstance(layer_in, nn.Linear):\n",
        "    nn.init.kaiming_normal_(layer_in.weight, mode='fan_in', nonlinearity='relu')\n",
        "    layer_in.bias.data.fill_(0.0)"
      ],
      "metadata": {
        "id": "DsQaMVqNIhyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualMLP(nn.Module):\n",
        "  def __init__(self, in_dim=784, out_dim=10, depth=3, units_per_block=128):\n",
        "    super(ResidualMLP, self).__init__()\n",
        "\n",
        "    self.in_dim = in_dim\n",
        "\n",
        "    self.initial_layer = nn.Linear(in_dim, units_per_block)\n",
        "\n",
        "    blocks_list = []\n",
        "    for i in range(depth):\n",
        "      blocks_list.append(ResidualLinearBlock((units_per_block)))\n",
        "    self.hidden_layers = nn.Sequential(*blocks_list)\n",
        "\n",
        "    self.final_layer = nn.Sequential(\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(units_per_block, out_dim)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    transformed_x = x.view(-1, self.in_dim) # flatten the input into (batch_dim, in_dim), using a -1 to tell .view to just make the math work\n",
        "\n",
        "    hidden_out = self.initial_layer(transformed_x)\n",
        "    hidden_out = self.hidden_layers(hidden_out)\n",
        "    output = self.final_layer(hidden_out)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "-Iaw2cU4GTp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualCNNClassifer(nn.Module):\n",
        "  def __init__(self, in_dim=784, out_dim=10, depth=3, units_per_block=128):\n",
        "    super(ResidualMLP, self).__init__()\n",
        "\n",
        "    self.in_dim = in_dim\n",
        "\n",
        "    self.initial_layer = nn.Linear(in_dim, units_per_block)\n",
        "\n",
        "    blocks_list = []\n",
        "    for i in range(depth):\n",
        "      blocks_list.append(ResidualLinearBlock((units_per_block)))\n",
        "    self.hidden_layers = nn.Sequential(*blocks_list)\n",
        "\n",
        "    self.final_layer = nn.Sequential(\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(units_per_block, out_dim)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    transformed_x = x.view(-1, self.in_dim) # flatten the input into (batch_dim, in_dim), using a -1 to tell .view to just make the math work\n",
        "\n",
        "    hidden_out = self.initial_layer(transformed_x)\n",
        "    hidden_out = self.hidden_layers(hidden_out)\n",
        "    output = self.final_layer(hidden_out)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "w5WrIHoOIXSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Settings\n",
        "\n",
        "MAX_EPOCHS = 2\n",
        "LR = 6e-4 * np.sqrt(2)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "my_model = ResidualMLP(depth=10).to('cuda')\n",
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(my_model.parameters(), lr=LR, weight_decay=1e-3)\n",
        "\n",
        "lossfn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "QvZlvebyH2sE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(seed=SEED)\n",
        "# Print training stats every LOG_FREQ minibatches\n",
        "LOG_FREQ = 200\n",
        "# Frequency for evaluating the validation metrics\n",
        "VAL_FREQ = 200\n",
        "# Load data using a Pytorch Dataset\n",
        "train_set_orig, test_set_orig = load_mnist_data(change_tensors=False)\n",
        "\n",
        "# We separate 10,000 training samples to create a validation set\n",
        "train_set_orig, val_set_orig = torch.utils.data.random_split(train_set_orig, [50000, 10000])\n",
        "\n",
        "# Create the corresponding DataLoaders for training and test\n",
        "g_seed = torch.Generator()\n",
        "g_seed.manual_seed(SEED)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set_orig,\n",
        "                                           shuffle=True,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           num_workers=2,\n",
        "                                           worker_init_fn=seed_worker,\n",
        "                                           generator=g_seed)\n",
        "val_loader = torch.utils.data.DataLoader(val_set_orig,\n",
        "                                         shuffle=True,\n",
        "                                         batch_size=256,\n",
        "                                         num_workers=2,\n",
        "                                         worker_init_fn=seed_worker,\n",
        "                                         generator=g_seed)\n",
        "test_loader = torch.utils.data.DataLoader(test_set_orig,\n",
        "                                          batch_size=256,\n",
        "                                          num_workers=2,\n",
        "                                          worker_init_fn=seed_worker,\n",
        "                                          generator=g_seed)\n",
        "\n",
        "# Run training\n",
        "metrics = {'train_loss':[],\n",
        "           'train_acc':[],\n",
        "           'val_loss':[],\n",
        "           'val_acc':[],\n",
        "           'val_idx':[]}\n",
        "\n",
        "step_idx = 0\n",
        "for epoch in tqdm(range(MAX_EPOCHS)):\n",
        "\n",
        "  running_loss, running_acc = 0., 0.\n",
        "\n",
        "  for batch_id, batch in enumerate(train_loader):\n",
        "    step_idx += 1\n",
        "    # Extract minibatch data and labels\n",
        "    data, labels = batch[0].to(DEVICE), batch[1].to(DEVICE)\n",
        "    # Just like before, refresh gradient accumulators.\n",
        "    # Note that this is now a method of the optimizer.\n",
        "    optimizer.zero_grad()\n",
        "    # Evaluate model and loss on minibatch\n",
        "\n",
        "    logits = my_model(data)\n",
        "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "    loss = lossfn(probs, labels)\n",
        "    acc = torch.mean(1.0 * (logits.argmax(dim=1) == labels))\n",
        "\n",
        "    # Compute gradients\n",
        "    loss.backward()\n",
        "    # Update parameters\n",
        "    # Note how all the magic in the update of the parameters is encapsulated by\n",
        "    # the optimizer class.\n",
        "    optimizer.step()\n",
        "    # Log metrics for plotting\n",
        "    metrics['train_loss'].append(loss.cpu().item())\n",
        "    metrics['train_acc'].append(acc.cpu().item())\n",
        "\n",
        "    if batch_id % VAL_FREQ == (VAL_FREQ - 1):\n",
        "      # Get an estimate of the validation accuracy with 100 batches\n",
        "      val_loss, val_acc = eval_model(my_model, lossfn, val_loader,\n",
        "                                     num_batches=100,\n",
        "                                     device=DEVICE)\n",
        "      metrics['val_idx'].append(step_idx)\n",
        "      metrics['val_loss'].append(val_loss)\n",
        "      metrics['val_acc'].append(val_acc)\n",
        "\n",
        "      print(f\"[VALID] Epoch {epoch + 1} - Batch {batch_id + 1} - \"\n",
        "            f\"Loss: {val_loss:.3f} - Acc: {100*val_acc:.3f}%\")\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.cpu().item()\n",
        "    running_acc += acc.cpu().item()\n",
        "    # Print every LOG_FREQ minibatches\n",
        "    if batch_id % LOG_FREQ == (LOG_FREQ-1):\n",
        "      print(f\"[TRAIN] Epoch {epoch + 1} - Batch {batch_id + 1} - \"\n",
        "            f\"Loss: {running_loss / LOG_FREQ:.3f} - \"\n",
        "            f\"Acc: {100 * running_acc / LOG_FREQ:.3f}%\")\n",
        "\n",
        "      running_loss, running_acc = 0., 0."
      ],
      "metadata": {
        "id": "AqL-xTFq9po6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553,
          "referenced_widgets": [
            "c50490db5fef49e09c7d1b8e775fe291",
            "66bc9433e310423ba3ce9d05def75ad2",
            "63abef7a165c42e9a96278e0554ecd0c",
            "edf3dc5d121a48b4a95baf3759b07840",
            "c89bc73b49844d33843252e8fe2845e4",
            "2880aeaf04dd46f5a4976ce89e2ed111",
            "3e808739eb7b4d2fac573c1cf359e0c4",
            "16711280c15a4d30bb1d16999e502261",
            "d48e4ec2c49d42a4be4efdf7c6c75285",
            "c6873bf432eb4fbeb5e877545a9a3e42",
            "3e425364dc8c42fda58d6ffc32873e9c"
          ]
        },
        "outputId": "02761d19-aff9-47ef-b3f0-6e37e1564bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed 2021 has been set.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c50490db5fef49e09c7d1b8e775fe291"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VALID] Epoch 1 - Batch 200 - Loss: 1.725 - Acc: 73.301%\n",
            "[TRAIN] Epoch 1 - Batch 200 - Loss: 1.885 - Acc: 57.781%\n",
            "[VALID] Epoch 1 - Batch 400 - Loss: 1.600 - Acc: 86.309%\n",
            "[TRAIN] Epoch 1 - Batch 400 - Loss: 1.651 - Acc: 81.297%\n",
            "[VALID] Epoch 1 - Batch 600 - Loss: 1.599 - Acc: 86.172%\n",
            "[TRAIN] Epoch 1 - Batch 600 - Loss: 1.608 - Acc: 85.344%\n",
            "[VALID] Epoch 1 - Batch 800 - Loss: 1.580 - Acc: 88.047%\n",
            "[TRAIN] Epoch 1 - Batch 800 - Loss: 1.597 - Acc: 86.500%\n",
            "[VALID] Epoch 1 - Batch 1000 - Loss: 1.564 - Acc: 89.873%\n",
            "[TRAIN] Epoch 1 - Batch 1000 - Loss: 1.582 - Acc: 87.922%\n",
            "[VALID] Epoch 1 - Batch 1200 - Loss: 1.562 - Acc: 89.912%\n",
            "[TRAIN] Epoch 1 - Batch 1200 - Loss: 1.580 - Acc: 88.141%\n",
            "[VALID] Epoch 1 - Batch 1400 - Loss: 1.587 - Acc: 87.520%\n",
            "[TRAIN] Epoch 1 - Batch 1400 - Loss: 1.577 - Acc: 88.422%\n",
            "[VALID] Epoch 2 - Batch 200 - Loss: 1.575 - Acc: 88.564%\n",
            "[TRAIN] Epoch 2 - Batch 200 - Loss: 1.573 - Acc: 88.797%\n",
            "[VALID] Epoch 2 - Batch 400 - Loss: 1.578 - Acc: 88.408%\n",
            "[TRAIN] Epoch 2 - Batch 400 - Loss: 1.584 - Acc: 87.547%\n",
            "[VALID] Epoch 2 - Batch 600 - Loss: 1.568 - Acc: 89.297%\n",
            "[TRAIN] Epoch 2 - Batch 600 - Loss: 1.573 - Acc: 88.797%\n",
            "[VALID] Epoch 2 - Batch 800 - Loss: 1.560 - Acc: 90.166%\n",
            "[TRAIN] Epoch 2 - Batch 800 - Loss: 1.617 - Acc: 84.453%\n",
            "[VALID] Epoch 2 - Batch 1000 - Loss: 1.572 - Acc: 88.975%\n",
            "[TRAIN] Epoch 2 - Batch 1000 - Loss: 1.564 - Acc: 89.719%\n",
            "[VALID] Epoch 2 - Batch 1200 - Loss: 1.622 - Acc: 83.887%\n",
            "[TRAIN] Epoch 2 - Batch 1200 - Loss: 1.561 - Acc: 90.062%\n",
            "[VALID] Epoch 2 - Batch 1400 - Loss: 1.633 - Acc: 82.715%\n",
            "[TRAIN] Epoch 2 - Batch 1400 - Loss: 1.663 - Acc: 79.781%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Various Testing Functions\n"
      ],
      "metadata": {
        "id": "usOjILTJIX_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# testing fns\n",
        "blocks_list = []\n",
        "for i in range(1,101):\n",
        "  blocks_list.append(ResidualLinearBlock((256)))\n",
        "BigBoy = nn.Sequential(*blocks_list)\n",
        "\n",
        "BigBoy.apply(weights_init)\n",
        "BigBoy.to('cuda')"
      ],
      "metadata": {
        "id": "2_FpbMjjH7o7",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42a37bd3-7aa0-4623-b4f8-1c2d4b619c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (1): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (2): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (3): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (4): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (5): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (6): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (7): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (8): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (9): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (10): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (11): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (12): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (13): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (14): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (15): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (16): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (17): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (18): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (19): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (20): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (21): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (22): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (23): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (24): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (25): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (26): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (27): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (28): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (29): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (30): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (31): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (32): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (33): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (34): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (35): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (36): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (37): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (38): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (39): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (40): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (41): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (42): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (43): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (44): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (45): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (46): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (47): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (48): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (49): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (50): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (51): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (52): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (53): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (54): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (55): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (56): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (57): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (58): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (59): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (60): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (61): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (62): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (63): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (64): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (65): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (66): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (67): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (68): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (69): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (70): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (71): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (72): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (73): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (74): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (75): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (76): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (77): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (78): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (79): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (80): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (81): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (82): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (83): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (84): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (85): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (86): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (87): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (88): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (89): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (90): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (91): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (92): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (93): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (94): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (95): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (96): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (97): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (98): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (99): ResidualLinearBlock(\n",
              "    (relu): ReLU()\n",
              "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = torch.randn(65536, 256).to('cuda')\n",
        "print(f'Variance of the input({batch.var()})')"
      ],
      "metadata": {
        "id": "klSGusVsrirw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d22918c-2125-47bd-b2e9-2e8fe5b06e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variance of the input(1.0000959634780884)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = BigBoy(batch)\n",
        "print(f'Variance of the output({out.var()})')"
      ],
      "metadata": {
        "id": "W1aOP2etsT1o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "079f80e8-61b9-4260-c50a-8d6e700c746b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variance of the output(0.4467712342739105)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing conv blocks\n",
        "blocks_list = []\n",
        "for i in range(1,100):\n",
        "  downsample = True if i%2==0 else False\n",
        "  blocks_list.append(ResidualConvBlock(2, 2, 3, 1, False))\n",
        "ConvBlocks = nn.Sequential(*blocks_list)\n",
        "\n",
        "ConvBlocks.apply(weights_init)\n",
        "ConvBlocks.to('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t7scsOo7Fe31",
        "outputId": "c0c6544f-22d1-4b7e-fe1e-7affd2b2e526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (1): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (2): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (3): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (4): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (5): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (6): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (7): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (8): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (9): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (10): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (11): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (12): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (13): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (14): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (15): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (16): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (17): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (18): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (19): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (20): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (21): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (22): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (23): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (24): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (25): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (26): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (27): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (28): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (29): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (30): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (31): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (32): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (33): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (34): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (35): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (36): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (37): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (38): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (39): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (40): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (41): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (42): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (43): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (44): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (45): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (46): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (47): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (48): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (49): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (50): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (51): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (52): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (53): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (54): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (55): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (56): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (57): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (58): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (59): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (60): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (61): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (62): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (63): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (64): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (65): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (66): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (67): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (68): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (69): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (70): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (71): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (72): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (73): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (74): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (75): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (76): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (77): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (78): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (79): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (80): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (81): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (82): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (83): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (84): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (85): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (86): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (87): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (88): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (89): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (90): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (91): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (92): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (93): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (94): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (95): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (96): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (97): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (98): ResidualConvBlock(\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (batchnorm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = torch.randn(2, 2, 256, 256).to('cuda')\n",
        "print(f'Variance of the input({batch.var()})')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sTeAINzGGfX",
        "outputId": "d4ba77c7-8ae3-43a9-ff42-8c264bfbaa0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variance of the input(0.9947458505630493)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = ConvBlocks(batch)\n",
        "print(f'Variance of the output({out.var()})')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTFsrox4GGfb",
        "outputId": "6aa17909-928e-47c3-8c6e-2029a830fb66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variance of the output(38.918663024902344)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "another commit\n"
      ],
      "metadata": {
        "id": "5SixHMOpXL7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "added a change\n"
      ],
      "metadata": {
        "id": "5wlmUowJZsNQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}